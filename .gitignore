llama_cpp_cache/*
cache/*
dist/*
models/*